{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Michael Toolin - Homework 2\n",
    "## NLP DS7337-403"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Windows-10-10.0.17134-SP0\n",
      "Python 3.6.6 |Anaconda custom (64-bit)| (default, Jun 28 2018, 11:27:44) [MSC v.1900 64 bit (AMD64)]\n",
      "NLTK 3.4\n",
      "re 2.2.1\n",
      "Numpy 1.15.0\n",
      "Scikit-Learn 0.19.1\n",
      "base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mtool\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mtool\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import platform; print(platform.platform())\n",
    "import sys; print (\"Python\", sys.version)\n",
    "import nltk; print(\"NLTK\", nltk.__version__)\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "from nltk import word_tokenize\n",
    "import urllib;#print(\"urllib\", urllib.__version__)\n",
    "from urllib import request\n",
    "import re; print(\"re\", re.__version__)\n",
    "import numpy as np; print(\"Numpy\",np.__version__)\n",
    "import matplotlib.pyplot as plt#; print(\"Matplotlib\",plt.__version__)\n",
    "import sklearn; print(\"Scikit-Learn\", sklearn.__version__)\n",
    "import os\n",
    "print (os.environ['CONDA_DEFAULT_ENV'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################\n",
    "#                                                         #\n",
    "#  downLoadBook                                           #\n",
    "#                                                         #\n",
    "# This procedure takes a url  as input                    #\n",
    "# and downloads the text from the URL and saves the       #\n",
    "# text locally in ./data directory                        #\n",
    "#                                                         #\n",
    "# Input:                                                  #\n",
    "#   url - url of text to download                         #\n",
    "#                                                         #\n",
    "# Output:                                                 #\n",
    "#   savedFilename.txt - locally stored text file          #\n",
    "#                                                         #\n",
    "###########################################################\n",
    "\n",
    "def downLoadBook (url):\n",
    "    response = request.urlopen(url)\n",
    "    localFile = response.read().decode('utf8')\n",
    "    if debug: \n",
    "        print ('Book read in...',len(localFile))\n",
    "    return localFile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################\n",
    "#                                                         #\n",
    "#  prepNLTK                                               #\n",
    "#                                                         #\n",
    "# This function takes in a raw text file and cleans it    #\n",
    "# by removing any header and trailer text                 #\n",
    "# The header and trailer identifying strings are passed   #\n",
    "# in as paramerters                                       #\n",
    "#                                                         #\n",
    "# Input:                                                  #\n",
    "#   string - raw text to clean                            #\n",
    "#   topSep - text defining end of header text             #\n",
    "#   botSep - text defining beginning of trailer text      #\n",
    "#                                                         #\n",
    "# Output:                                                 #\n",
    "#   text - text in NLTK format for processing             #\n",
    "#                                                         #\n",
    "###########################################################\n",
    "\n",
    "def prepNLTK(string, topSep, botSep):\n",
    "    newRaw = string.split(topSep,2)[-1]\n",
    "    newerRaw = newRaw.split(botSep,1)[0]\n",
    "    newerRaw1 = newerRaw.strip('\\n')\n",
    "    clean = newerRaw1.strip('\\r')\n",
    "    tokens = word_tokenize(clean)\n",
    "    text = nltk.Text(tokens)\n",
    "    \n",
    "# For debugging\n",
    "    if debug:\n",
    "        print ('------------------------')\n",
    "        print('Raw string ',len(string),type(string))\n",
    "        print ('Header removed ',len(newRaw),type(newRaw))\n",
    "        print ('Trailer removed ',len(newerRaw),type(newerRaw))\n",
    "        print ('Removed n ',len(newerRaw1),type(newerRaw1))\n",
    "        print ('Removed r ',len(clean),type(clean))\n",
    "        print ('Tokens ', len(tokens), type(tokens))\n",
    "        print (tokens[:10])\n",
    "        print (type(text))\n",
    "        print (text[100:110])\n",
    "        print (text.collocations())\n",
    "        print (newerRaw[-63:-1])\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createCorpusList(bookList):\n",
    "    \n",
    "# read each url and calculate stats, save in textStats list\n",
    "# Read in the three text files\n",
    "#    Book 1 - McGuffey's Third Eclectic Reader - pg14766.txt\n",
    "#    Book 2 - McGuffey's Fourth Eclectic Reader - pg14880.txt\n",
    "#    Book 3 - McGuffey's Fifth Eclectic Reader - pg15040.txt\n",
    "\n",
    "    bookList.append({'title': \"McGuffeys Third Eclectic Reader\",\n",
    "                     'url': 'http://www.gutenberg.org/cache/epub/14766/pg14766.txt',\n",
    "                     'topSep': 'LESSON',\n",
    "                     'botSep': 'End of the Project Gutenberg EBook ',\n",
    "                     'totalWords': 0,\n",
    "                     'lexDiv': 0,\n",
    "                     'vocSize' : 0,\n",
    "                     'normalizedLongLexScore': 0,\n",
    "                     'numLongWords': '',\n",
    "                     'longWordLex': 0})\n",
    "             \n",
    "    bookList.append({'title': \"McGuffeys Fourth Eclectic Reader\",\n",
    "                     'url': \"http://www.gutenberg.org/cache/epub/14880/pg14880.txt\",\n",
    "                     'topSep': 'INTRODUCTORY MATTER',\n",
    "                     'botSep': 'End of the Project Gutenberg EBook ',\n",
    "                     'totalWords': 0,\n",
    "                     'lexDiv': 0,\n",
    "                     'vocSize' : 0,\n",
    "                     'normalizedLongLexScore': 0,\n",
    "                     'numLongWords': '',\n",
    "                     'longWordLex': 0})\n",
    "    \n",
    "    bookList.append({'title': \"McGuffeys Fifth Eclectic Reader\",\n",
    "                     'url': \"http://www.gutenberg.org/cache/epub/15040/pg15040.txt\",\n",
    "                     'topSep': 'CONTENTS',\n",
    "                     'botSep': '*** END OF THIS PROJECT GUTENBERG EBOOK ',\n",
    "                     'totalWords': 0,\n",
    "                     'lexDiv': 0,\n",
    "                     'vocSize' : 0,\n",
    "                     'normalizedLongLexScore': 0,\n",
    "                     'numLongWords': '',\n",
    "                     'longWordLex': 0})\n",
    "    return bookList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(myScore):\n",
    "    maxValue = max(myScore)\n",
    "\n",
    "    return [(score/maxValue) for score in myScore]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################\n",
    "#                                         #\n",
    "# Various text/word scoring routines      #\n",
    "#                                         #\n",
    "###########################################\n",
    "\n",
    "#\n",
    "# Returns the Lexical Diverstiy\n",
    "#\n",
    "def lexicalDiversity (text):\n",
    "    return len(set(text)) / len(text)\n",
    "\n",
    "def percentage (count, total):\n",
    "    return (count/total) * 100\n",
    "#\n",
    "# Returns the Vocabulary Size\n",
    "#\n",
    "def vocabularySize (text):\n",
    "    return len(set(text))\n",
    "\n",
    "###################################################################\n",
    "#                                                                 #\n",
    "# longWordsStats                                                  #\n",
    "# Returns the dictionary filled in with Long Words Stats          #\n",
    "#   Input:                                                        #\n",
    "#      text    - the text to analyze                              #\n",
    "#      id      - the dictionary to fill in                        #\n",
    "#      wordLen - The number of letters that defines a long word   #\n",
    "#                                                                 #\n",
    "#   Output: id dictionary values filled in                        #\n",
    "#      numLongWords  - number of unique long words                #\n",
    "#      freqLongWords - long words appearing more than wordFreq    #\n",
    "#                      times                                      #\n",
    "#      numFreqLngWds - number of frequent long words              #\n",
    "#      lordWordLex   - lexical score of the set of long words     #\n",
    "#                                                                 #\n",
    "###################################################################\n",
    "\n",
    "def longWordsStats (text, ids ,wordLen):\n",
    "    \n",
    "    vocab = set(text)\n",
    "    longWordsList = [w for w in vocab if len(w) > wordLen]\n",
    "    longWordsCount = len(longWordsList)\n",
    "    longWordLex = (len(set(longWordsList)))/ (len(text))\n",
    "    ids['longWordLex'] = longWordLex\n",
    "    ids['numLongWords'] = len(longWordsList)\n",
    "    if True:\n",
    "        print('Number of Long words = ', longWordsCount)\n",
    "        print('Long Word Lex', ids['longWordLex'])\n",
    "    return (ids)\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Long words =  62\n",
      "Long Word Lex 0.0018322595898102724\n",
      "Number of Long words =  570\n",
      "Long Word Lex 0.00710811821922933\n",
      "Number of Long words =  1080\n",
      "Long Word Lex 0.008806980347386447\n"
     ]
    }
   ],
   "source": [
    "debug = 0\n",
    "bookList = []\n",
    "textStats = []\n",
    "longLexScoreList =[]\n",
    "lexScoreList = []\n",
    "vocabScoreList = []\n",
    "totalWordList = []\n",
    "totalLongWrdList = []\n",
    "\n",
    "createCorpusList (bookList)\n",
    "for ids in bookList: \n",
    "    raw = downLoadBook(ids['url'])\n",
    "    text = prepNLTK(raw, str(ids['topSep']), ids['botSep'])\n",
    "    ids['lexDiv'] = lexicalDiversity(text)\n",
    "    ids['vocSize'] = vocabularySize(text)\n",
    "    ids['totalWords'] = len(raw)\n",
    "    ids = longWordsStats(text, ids, 10)\n",
    "    longLexScoreList.append(ids['longWordLex'])\n",
    "    lexScoreList.append(ids['lexDiv'])\n",
    "    vocabScoreList.append(ids['vocSize'])\n",
    "    totalWordList.append(ids['totalWords'])\n",
    "    totalLongWrdList.append(ids['numLongWords'])\n",
    "    \n",
    "    \n",
    "    \n",
    "longLexScoreList = normalize(longLexScoreList)\n",
    "lexScoreList = normalize(lexScoreList)\n",
    "vocabScoreList = normalize(vocabScoreList)\n",
    "totalWordList = normalize(totalWordList)\n",
    "totalLongWrdList = normalize(totalLongWrdList)\n",
    "\n",
    "    \n",
    "\n",
    "#print(\"Book List - \", bookList)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "booklist =  [{'title': 'McGuffeys Third Eclectic Reader', 'url': 'http://www.gutenberg.org/cache/epub/14766/pg14766.txt', 'topSep': 'LESSON', 'botSep': 'End of the Project Gutenberg EBook ', 'totalWords': 168150, 'lexDiv': 0.11806253324664578, 'vocSize': 3995, 'normalizedLongLexScore': 0, 'numLongWords': 62, 'longWordLex': 0.0018322595898102724}, {'title': 'McGuffeys Fourth Eclectic Reader', 'url': 'http://www.gutenberg.org/cache/epub/14880/pg14880.txt', 'topSep': 'INTRODUCTORY MATTER', 'botSep': 'End of the Project Gutenberg EBook ', 'totalWords': 388599, 'lexDiv': 0.12267115600448934, 'vocSize': 9837, 'normalizedLongLexScore': 0, 'numLongWords': 570, 'longWordLex': 0.00710811821922933}, {'title': 'McGuffeys Fifth Eclectic Reader', 'url': 'http://www.gutenberg.org/cache/epub/15040/pg15040.txt', 'topSep': 'CONTENTS', 'botSep': '*** END OF THIS PROJECT GUTENBERG EBOOK ', 'totalWords': 605269, 'lexDiv': 0.11291690450950012, 'vocSize': 13847, 'normalizedLongLexScore': 0, 'numLongWords': 1080, 'longWordLex': 0.008806980347386447}]\n",
      "id = {'title': 'McGuffeys Fifth Eclectic Reader', 'url': 'http://www.gutenberg.org/cache/epub/15040/pg15040.txt', 'topSep': 'CONTENTS', 'botSep': '*** END OF THIS PROJECT GUTENBERG EBOOK ', 'totalWords': 605269, 'lexDiv': 0.11291690450950012, 'vocSize': 13847, 'normalizedLongLexScore': 0, 'numLongWords': 1080, 'longWordLex': 0.008806980347386447}\n",
      "norm Lex = [0.9624310807205982, 1.0, 0.920484555516602]\n",
      "norm Long Lex =  [0.2080462902763275, 0.8071004974297156, 1.0]\n",
      "vocabScoreList =  [0.2885101466021521, 0.7104065862641727, 1.0]\n",
      "totalwordlis =  [0.27781036200433196, 0.6420269334791638, 1.0]\n",
      "totalLngwordList =  [0.05740740740740741, 0.5277777777777778, 1.0]\n"
     ]
    }
   ],
   "source": [
    "print('booklist = ', bookList)\n",
    "print('id =', ids)\n",
    "print (\"norm Lex =\", lexScoreList)\n",
    "print ('norm Long Lex = ', longLexScoreList)\n",
    "print ('vocabScoreList = ',vocabScoreList)\n",
    "print ('totalwordlis = ',totalWordList)\n",
    "print ('totalLngwordList = ',totalLongWrdList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.hist(longLexScoreList, label='Long Lex Score')\n",
    "plt.hist(lexScoreList, label = 'Lex Score')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion of findings\n",
    "The three books examined were each part of McGuffey's Eclectic Reader series. I examined books for third graders, fourth graders and fifth graders. I found that the total size of each book increased with grade level, with the fifth grade book being almost four times as long as the third grade book. This is an expected result; as children get older they are able to read longer books.  Two lexical statistics are examined to measure the complexity of each of the texts.  The first is the vocabulary which is the set of unique tokens in the text.  The second statistic is lexical diversity which is the proportion of unique tokens in a text to the total number of tokens in the same text. When vocabulary size is examined, the size more than doubles from third to fourth grade, and then increases appoximately fifty percent from fourth to fifth grade.  This is also an expected result as we would think a fourth grade vocabulary is much larger than that of third grade, and the fifth grade vocabulary continues to increase compared to fourth grade.  The lexical diversity remains relatively steady between the three texts. This is expected since lexical diversity measures the number of unique words to the total size of the text and in an education text the goal is to teach the student.  Even though vocabulary is increasing, the mix of unique words does not so the text is not confusing to the student.\n",
    "\n",
    "Since lexical diversity is a measure of range of use of the vocabulary in the text, it follows that a text with a higher vocabulary **and** a higher lexical diverity would indicate a text with a higher reading level. A large vocabulary alone indicates a large number of unique words, but if they are only used once, or there are several sentences used as definitions, this could lead to large vocabulary, but a low lexical diversity.  Conversely, a lower vocabulary with a high lexical diversity could indicate a shorter text and only shows the small number of unique words are mixed in well in the text.  The combination of a larger vocabulary (usually indicating longer text) and a higher lexical diversity indicates more words used in a unique fashion. This type of text would be a appropriate for a higher reading level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
